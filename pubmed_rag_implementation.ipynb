{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":7133139,"sourceType":"datasetVersion","datasetId":4115706}],"dockerImageVersionId":30823,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install transformers datasets peft faiss-cpu sentence-transformers faiss-gpu\n!pip install bitsandbytes peft accelerate gradio trl","metadata":{"_uuid":"a9e004c4-deb1-47cf-b009-c2558b0df3d8","_cell_guid":"5bcb0a10-ef01-4185-81ee-6ab0af7efafe","trusted":true,"collapsed":true,"execution":{"iopub.status.busy":"2025-01-12T17:25:19.567133Z","iopub.execute_input":"2025-01-12T17:25:19.567413Z","iopub.status.idle":"2025-01-12T17:25:51.764108Z","shell.execute_reply.started":"2025-01-12T17:25:19.567388Z","shell.execute_reply":"2025-01-12T17:25:51.763256Z"},"jupyter":{"outputs_hidden":true}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.44.2)\nRequirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (3.2.0)\nCollecting peft\n  Downloading peft-0.14.0-py3-none-any.whl.metadata (13 kB)\nCollecting faiss-cpu\n  Downloading faiss_cpu-1.9.0.post1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.4 kB)\nCollecting sentence-transformers\n  Downloading sentence_transformers-3.3.1-py3-none-any.whl.metadata (10 kB)\nCollecting faiss-gpu\n  Downloading faiss_gpu-1.7.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.4 kB)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\nRequirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.24.7)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.1)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.9.11)\nRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\nRequirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\nRequirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\nRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.5)\nRequirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (18.1.0)\nRequirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\nRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.1.4)\nRequirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.5.0)\nRequirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\nRequirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets) (2024.6.1)\nRequirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.10.5)\nRequirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from peft) (5.9.5)\nRequirement already satisfied: torch>=1.13.0 in /usr/local/lib/python3.10/dist-packages (from peft) (2.4.1+cu121)\nRequirement already satisfied: accelerate>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from peft) (0.34.2)\nCollecting huggingface-hub<1.0,>=0.23.2 (from transformers)\n  Downloading huggingface_hub-0.27.1-py3-none-any.whl.metadata (13 kB)\nRequirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.2.2)\nRequirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.13.1)\nRequirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (10.4.0)\nRequirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.0)\nRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (24.2.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.1.0)\nRequirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.11.1)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.8.30)\nRequirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (1.13.3)\nRequirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (3.3)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (3.1.4)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\nRequirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.1)\nRequirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers) (1.4.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers) (3.5.0)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.13.0->peft) (2.1.5)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.13.0->peft) (1.3.0)\nDownloading peft-0.14.0-py3-none-any.whl (374 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m374.8/374.8 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n\u001b[?25hDownloading faiss_cpu-1.9.0.post1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (27.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27.5/27.5 MB\u001b[0m \u001b[31m68.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading sentence_transformers-3.3.1-py3-none-any.whl (268 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m17.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading faiss_gpu-1.7.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (85.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.5/85.5 MB\u001b[0m \u001b[31m20.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading huggingface_hub-0.27.1-py3-none-any.whl (450 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m450.7/450.7 kB\u001b[0m \u001b[31m24.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: faiss-gpu, faiss-cpu, huggingface-hub, sentence-transformers, peft\n  Attempting uninstall: huggingface-hub\n    Found existing installation: huggingface-hub 0.24.7\n    Uninstalling huggingface-hub-0.24.7:\n      Successfully uninstalled huggingface-hub-0.24.7\nSuccessfully installed faiss-cpu-1.9.0.post1 faiss-gpu-1.7.2 huggingface-hub-0.27.1 peft-0.14.0 sentence-transformers-3.3.1\nCollecting bitsandbytes\n  Downloading bitsandbytes-0.45.0-py3-none-manylinux_2_24_x86_64.whl.metadata (2.9 kB)\nRequirement already satisfied: peft in /usr/local/lib/python3.10/dist-packages (0.14.0)\nRequirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (0.34.2)\nCollecting gradio\n  Downloading gradio-5.12.0-py3-none-any.whl.metadata (16 kB)\nCollecting trl\n  Downloading trl-0.13.0-py3-none-any.whl.metadata (11 kB)\nRequirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from bitsandbytes) (2.4.1+cu121)\nRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from bitsandbytes) (1.26.4)\nRequirement already satisfied: typing_extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from bitsandbytes) (4.12.2)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from peft) (24.1)\nRequirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from peft) (5.9.5)\nRequirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from peft) (6.0.2)\nRequirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (from peft) (4.44.2)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from peft) (4.66.5)\nRequirement already satisfied: safetensors in /usr/local/lib/python3.10/dist-packages (from peft) (0.4.5)\nRequirement already satisfied: huggingface-hub>=0.25.0 in /usr/local/lib/python3.10/dist-packages (from peft) (0.27.1)\nRequirement already satisfied: aiofiles<24.0,>=22.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (22.1.0)\nRequirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.7.1)\nCollecting fastapi<1.0,>=0.115.2 (from gradio)\n  Downloading fastapi-0.115.6-py3-none-any.whl.metadata (27 kB)\nCollecting ffmpy (from gradio)\n  Downloading ffmpy-0.5.0-py3-none-any.whl.metadata (3.0 kB)\nCollecting gradio-client==1.5.4 (from gradio)\n  Downloading gradio_client-1.5.4-py3-none-any.whl.metadata (7.1 kB)\nCollecting httpx>=0.24.1 (from gradio)\n  Downloading httpx-0.28.1-py3-none-any.whl.metadata (7.1 kB)\nRequirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.1.4)\nRequirement already satisfied: markupsafe~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.1.5)\nCollecting orjson~=3.0 (from gradio)\n  Downloading orjson-3.10.14-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (41 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.8/41.8 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.1.4)\nRequirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (10.4.0)\nRequirement already satisfied: pydantic>=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.9.2)\nRequirement already satisfied: pydub in /usr/local/lib/python3.10/dist-packages (from gradio) (0.25.1)\nCollecting python-multipart>=0.0.18 (from gradio)\n  Downloading python_multipart-0.0.20-py3-none-any.whl.metadata (1.8 kB)\nCollecting ruff>=0.2.2 (from gradio)\n  Downloading ruff-0.9.1-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (25 kB)\nCollecting safehttpx<0.2.0,>=0.1.6 (from gradio)\n  Downloading safehttpx-0.1.6-py3-none-any.whl.metadata (4.2 kB)\nCollecting semantic-version~=2.0 (from gradio)\n  Downloading semantic_version-2.10.0-py2.py3-none-any.whl.metadata (9.7 kB)\nCollecting starlette<1.0,>=0.40.0 (from gradio)\n  Downloading starlette-0.45.2-py3-none-any.whl.metadata (6.3 kB)\nCollecting tomlkit<0.14.0,>=0.12.0 (from gradio)\n  Downloading tomlkit-0.13.2-py3-none-any.whl.metadata (2.7 kB)\nRequirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.12.5)\nCollecting uvicorn>=0.14.0 (from gradio)\n  Downloading uvicorn-0.34.0-py3-none-any.whl.metadata (6.5 kB)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from gradio-client==1.5.4->gradio) (2024.6.1)\nRequirement already satisfied: websockets<15.0,>=10.0 in /usr/local/lib/python3.10/dist-packages (from gradio-client==1.5.4->gradio) (14.1)\nRequirement already satisfied: datasets>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from trl) (3.2.0)\nRequirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from trl) (13.8.1)\nCollecting transformers (from peft)\n  Downloading transformers-4.48.0-py3-none-any.whl.metadata (44 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.4/44.4 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio) (3.10)\nRequirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\nRequirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio) (1.2.2)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets>=2.21.0->trl) (3.16.1)\nRequirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.21.0->trl) (18.1.0)\nRequirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.21.0->trl) (0.3.8)\nRequirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.21.0->trl) (2.32.3)\nRequirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets>=2.21.0->trl) (3.5.0)\nRequirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.21.0->trl) (0.70.16)\nRequirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets>=2.21.0->trl) (3.10.5)\nCollecting starlette<1.0,>=0.40.0 (from gradio)\n  Downloading starlette-0.41.3-py3-none-any.whl.metadata (6.0 kB)\nRequirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (2024.8.30)\nCollecting httpcore==1.* (from httpx>=0.24.1->gradio)\n  Downloading httpcore-1.0.7-py3-none-any.whl.metadata (21 kB)\nCollecting h11<0.15,>=0.13 (from httpcore==1.*->httpx>=0.24.1->gradio)\n  Downloading h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio) (2.8.2)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio) (2024.2)\nRequirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio) (2024.1)\nRequirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->gradio) (0.7.0)\nRequirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->gradio) (2.23.4)\nRequirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (1.13.3)\nRequirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (3.3)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers->peft) (2024.9.11)\nCollecting tokenizers<0.22,>=0.21 (from transformers->peft)\n  Downloading tokenizers-0.21.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\nRequirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (8.1.7)\nRequirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->trl) (3.0.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->trl) (2.18.0)\nRequirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.21.0->trl) (2.4.0)\nRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.21.0->trl) (1.3.1)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.21.0->trl) (24.2.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.21.0->trl) (1.4.1)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.21.0->trl) (6.1.0)\nRequirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.21.0->trl) (1.11.1)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.21.0->trl) (4.0.3)\nRequirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->trl) (0.1.2)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.16.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets>=2.21.0->trl) (3.3.2)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets>=2.21.0->trl) (2.2.3)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->bitsandbytes) (1.3.0)\nDownloading bitsandbytes-0.45.0-py3-none-manylinux_2_24_x86_64.whl (69.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m69.1/69.1 MB\u001b[0m \u001b[31m25.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading gradio-5.12.0-py3-none-any.whl (57.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.6/57.6 MB\u001b[0m \u001b[31m28.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading gradio_client-1.5.4-py3-none-any.whl (321 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m321.4/321.4 kB\u001b[0m \u001b[31m18.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading trl-0.13.0-py3-none-any.whl (293 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m293.4/293.4 kB\u001b[0m \u001b[31m20.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading fastapi-0.115.6-py3-none-any.whl (94 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.8/94.8 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading httpx-0.28.1-py3-none-any.whl (73 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.5/73.5 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading httpcore-1.0.7-py3-none-any.whl (78 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.6/78.6 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading orjson-3.10.14-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (130 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.4/130.4 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading python_multipart-0.0.20-py3-none-any.whl (24 kB)\nDownloading ruff-0.9.1-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.3/11.3 MB\u001b[0m \u001b[31m105.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n\u001b[?25hDownloading safehttpx-0.1.6-py3-none-any.whl (8.7 kB)\nDownloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\nDownloading starlette-0.41.3-py3-none-any.whl (73 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.2/73.2 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading tomlkit-0.13.2-py3-none-any.whl (37 kB)\nDownloading transformers-4.48.0-py3-none-any.whl (9.7 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.7/9.7 MB\u001b[0m \u001b[31m115.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading uvicorn-0.34.0-py3-none-any.whl (62 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.3/62.3 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading ffmpy-0.5.0-py3-none-any.whl (6.0 kB)\nDownloading h11-0.14.0-py3-none-any.whl (58 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading tokenizers-0.21.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m81.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hInstalling collected packages: tomlkit, semantic-version, ruff, python-multipart, orjson, h11, ffmpy, uvicorn, starlette, httpcore, tokenizers, httpx, fastapi, bitsandbytes, transformers, safehttpx, gradio-client, gradio, trl\n  Attempting uninstall: tokenizers\n    Found existing installation: tokenizers 0.19.1\n    Uninstalling tokenizers-0.19.1:\n      Successfully uninstalled tokenizers-0.19.1\n  Attempting uninstall: transformers\n    Found existing installation: transformers 4.44.2\n    Uninstalling transformers-4.44.2:\n      Successfully uninstalled transformers-4.44.2\nSuccessfully installed bitsandbytes-0.45.0 fastapi-0.115.6 ffmpy-0.5.0 gradio-5.12.0 gradio-client-1.5.4 h11-0.14.0 httpcore-1.0.7 httpx-0.28.1 orjson-3.10.14 python-multipart-0.0.20 ruff-0.9.1 safehttpx-0.1.6 semantic-version-2.10.0 starlette-0.41.3 tokenizers-0.21.0 tomlkit-0.13.2 transformers-4.48.0 trl-0.13.0 uvicorn-0.34.0\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"from huggingface_hub import notebook_login\nnotebook_login()","metadata":{"_uuid":"a77930bc-4a24-4bec-a91f-319cca504674","_cell_guid":"8ac5df66-5dab-47cf-b8ce-82759aae15a8","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-01-12T17:25:55.120088Z","iopub.execute_input":"2025-01-12T17:25:55.120691Z","iopub.status.idle":"2025-01-12T17:25:55.376858Z","shell.execute_reply.started":"2025-01-12T17:25:55.120654Z","shell.execute_reply":"2025-01-12T17:25:55.375854Z"},"jupyter":{"outputs_hidden":false}},"outputs":[{"output_type":"display_data","data":{"text/plain":"VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"09cbf19525f842a88a067b6d4bbedec5"}},"metadata":{}}],"execution_count":2},{"cell_type":"code","source":"from transformers import LlamaTokenizer,PreTrainedTokenizerFast\nfrom datasets import load_dataset\n\n# Load the PubMed QA dataset\npubmed = load_dataset('pubmed_qa', 'pqa_labeled', split='train')\n\n# Load the Llama tokenizer\ntokenizer = PreTrainedTokenizerFast.from_pretrained('meta-llama/Llama-3.2-1B-Instruct')\ntokenizer.pad_token = tokenizer.eos_token\n\n# Tokenize function with special tokens for question and context\ndef tokenize_function(examples):\n    # Concatenate the question and context with special tokens\n    inputs = [f\"<question> {q} <context> {c}\" for q, c in zip(examples['question'], examples['context'])]\n    \n    # Tokenize the inputs and long answers\n    tokenized_inputs = tokenizer(\n        inputs,\n        truncation=True,\n        padding='max_length',\n        max_length=512,\n    )\n    \n    # Tokenize the long answers\n    tokenized_answers = tokenizer(\n        examples['long_answer'],\n        truncation=True,\n        padding='max_length',\n        max_length=512,\n    )[\"input_ids\"]\n\n    # Set the tokenized long answers as labels for training\n    tokenized_inputs[\"labels\"] = tokenized_answers\n    return tokenized_inputs\n\n# Tokenize the dataset\ntokenized_pubmed = pubmed.map(tokenize_function, batched=True)\n\n# Display the tokenized dataset\nprint(tokenized_pubmed)","metadata":{"_uuid":"befd7fe7-08d5-4acf-8aad-11dbee2d177b","_cell_guid":"a40db5fa-ae45-4f2e-ba78-a05715876148","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-01-12T17:26:16.230043Z","iopub.execute_input":"2025-01-12T17:26:16.230383Z","iopub.status.idle":"2025-01-12T17:26:22.055660Z","shell.execute_reply.started":"2025-01-12T17:26:16.230356Z","shell.execute_reply":"2025-01-12T17:26:22.054660Z"},"jupyter":{"outputs_hidden":false}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/1000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1ca9b6ebc94a4116b650434e540212a2"}},"metadata":{}},{"name":"stdout","text":"Dataset({\n    features: ['pubid', 'question', 'context', 'long_answer', 'final_decision', 'input_ids', 'attention_mask', 'labels'],\n    num_rows: 1000\n})\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"print(tokenized_pubmed[0])","metadata":{"_uuid":"565ddc63-f6a5-4e04-8fff-42bb4d33c03f","_cell_guid":"b9953228-1889-48a7-93e4-6f4c7e7595ba","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-01-11T18:25:43.011530Z","iopub.execute_input":"2025-01-11T18:25:43.012048Z","iopub.status.idle":"2025-01-11T18:25:43.018417Z","shell.execute_reply.started":"2025-01-11T18:25:43.012022Z","shell.execute_reply":"2025-01-11T18:25:43.017568Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from transformers import LlamaForCausalLM, AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig, HfArgumentParser, TrainingArguments, pipeline, logging, TextStreamer\nfrom peft import LoraConfig, PeftModel, prepare_model_for_kbit_training, get_peft_model\nimport os,torch, wandb, platform, gradio, warnings\nfrom datasets import load_dataset\nfrom trl import SFTTrainer\n\nbnb_config = BitsAndBytesConfig(\n    load_in_4bit= True,\n    bnb_4bit_quant_type= \"nf4\",\n    bnb_4bit_compute_dtype= torch.float16,\n    bnb_4bit_use_double_quant= False,\n)\n\n# Load the model using bitsandbytes (with 4-bit quantization)\nmodel = LlamaForCausalLM.from_pretrained(\n    'meta-llama/Llama-3.2-1B-Instruct', quantization_config=bnb_config)\n\n# Apply LoRA or QLoRA config to the model\nlora_config = LoraConfig(\n    r=8,                 # Rank of the LoRA matrix\n    lora_alpha=16,       # Scaling factor for LoRA\n    lora_dropout=0.1,    # Dropout rate\n    bias=\"none\"          # No bias for LoRA layers\n)\n\n# Apply LoRA to the model\nmodel = get_peft_model(model, lora_config)\n\n# Ensure the model is in evaluation mode to verify it works\nmodel.eval()","metadata":{"_uuid":"71acb9d1-0541-40a3-9a1e-8125d96c080b","_cell_guid":"232180f2-978c-421c-af15-d3081274bcc6","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-01-12T17:26:26.670371Z","iopub.execute_input":"2025-01-12T17:26:26.670674Z","iopub.status.idle":"2025-01-12T17:27:43.808648Z","shell.execute_reply.started":"2025-01-12T17:26:26.670651Z","shell.execute_reply":"2025-01-12T17:27:43.807471Z"},"jupyter":{"outputs_hidden":false}},"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/877 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f55e302f13d045c3a0d14428973a6627"}},"metadata":{}},{"name":"stderr","text":"`low_cpu_mem_usage` was None, now default to True since model is quantized.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/2.47G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a1089e463116429d8f7d3c715614e1d5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/189 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a6f41e47418c499e8054f78f1f7590ed"}},"metadata":{}},{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"PeftModel(\n  (base_model): LoraModel(\n    (model): LlamaForCausalLM(\n      (model): LlamaModel(\n        (embed_tokens): Embedding(128256, 2048)\n        (layers): ModuleList(\n          (0-15): 16 x LlamaDecoderLayer(\n            (self_attn): LlamaAttention(\n              (q_proj): lora.Linear4bit(\n                (base_layer): Linear4bit(in_features=2048, out_features=2048, bias=False)\n                (lora_dropout): ModuleDict(\n                  (default): Dropout(p=0.1, inplace=False)\n                )\n                (lora_A): ModuleDict(\n                  (default): Linear(in_features=2048, out_features=8, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (default): Linear(in_features=8, out_features=2048, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n                (lora_magnitude_vector): ModuleDict()\n              )\n              (k_proj): Linear4bit(in_features=2048, out_features=512, bias=False)\n              (v_proj): lora.Linear4bit(\n                (base_layer): Linear4bit(in_features=2048, out_features=512, bias=False)\n                (lora_dropout): ModuleDict(\n                  (default): Dropout(p=0.1, inplace=False)\n                )\n                (lora_A): ModuleDict(\n                  (default): Linear(in_features=2048, out_features=8, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (default): Linear(in_features=8, out_features=512, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n                (lora_magnitude_vector): ModuleDict()\n              )\n              (o_proj): Linear4bit(in_features=2048, out_features=2048, bias=False)\n            )\n            (mlp): LlamaMLP(\n              (gate_proj): Linear4bit(in_features=2048, out_features=8192, bias=False)\n              (up_proj): Linear4bit(in_features=2048, out_features=8192, bias=False)\n              (down_proj): Linear4bit(in_features=8192, out_features=2048, bias=False)\n              (act_fn): SiLU()\n            )\n            (input_layernorm): LlamaRMSNorm((2048,), eps=1e-05)\n            (post_attention_layernorm): LlamaRMSNorm((2048,), eps=1e-05)\n          )\n        )\n        (norm): LlamaRMSNorm((2048,), eps=1e-05)\n        (rotary_emb): LlamaRotaryEmbedding()\n      )\n      (lm_head): Linear(in_features=2048, out_features=128256, bias=False)\n    )\n  )\n)"},"metadata":{}}],"execution_count":4},{"cell_type":"code","source":"from trl import SFTTrainer\nfrom transformers import TrainingArguments\n\n# Define training arguments\ntraining_args = TrainingArguments(\n    output_dir=\"./kaggle/working/fine_tuned_model\",  # Directory to save the model\n    # evaluation_strategy=\"epoch\",  # Evaluate the model after every epoch\n    learning_rate=5e-5,  # Learning rate for fine-tuning\n    per_device_train_batch_size=1,  # Batch size per GPU\n    per_device_eval_batch_size=1,  # Batch size per GPU during evaluation\n    num_train_epochs=2,  # Number of epochs\n    weight_decay=0.01,  # Regularization to prevent overfitting\n    save_total_limit=1,  # Limit the number of saved models\n    logging_dir='./logs',  # Directory to store logs\n    logging_steps=20,  # Log every 20 steps\n    report_to=\"tensorboard\",  # Report training to TensorBoard\n    fp16=True\n)\n\n\n# Initialize the SFTTrainer\ntrainer = SFTTrainer(\n    model=model,                         # The model to be trained\n    args=training_args,                  # Training arguments\n    train_dataset=tokenized_pubmed,      # Tokenized dataset\n)\n\n# Start training\ntrainer.train()","metadata":{"_uuid":"ddf69ecd-bb26-4872-afd4-bc60df80eb8c","_cell_guid":"c01427b2-1d14-4f40-bc9d-b9c303216938","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-01-12T17:27:43.810084Z","iopub.execute_input":"2025-01-12T17:27:43.810368Z","iopub.status.idle":"2025-01-12T17:44:34.614646Z","shell.execute_reply.started":"2025-01-12T17:27:43.810347Z","shell.execute_reply":"2025-01-12T17:44:34.613928Z"},"jupyter":{"outputs_hidden":false}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/accelerate/accelerator.py:494: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n  self.scaler = torch.cuda.amp.GradScaler(**kwargs)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='2000' max='2000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [2000/2000 16:48, Epoch 2/2]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>20</td>\n      <td>2.355400</td>\n    </tr>\n    <tr>\n      <td>40</td>\n      <td>2.305600</td>\n    </tr>\n    <tr>\n      <td>60</td>\n      <td>2.280600</td>\n    </tr>\n    <tr>\n      <td>80</td>\n      <td>2.142000</td>\n    </tr>\n    <tr>\n      <td>100</td>\n      <td>1.904000</td>\n    </tr>\n    <tr>\n      <td>120</td>\n      <td>1.831100</td>\n    </tr>\n    <tr>\n      <td>140</td>\n      <td>1.821600</td>\n    </tr>\n    <tr>\n      <td>160</td>\n      <td>1.837400</td>\n    </tr>\n    <tr>\n      <td>180</td>\n      <td>1.723900</td>\n    </tr>\n    <tr>\n      <td>200</td>\n      <td>1.878900</td>\n    </tr>\n    <tr>\n      <td>220</td>\n      <td>1.830800</td>\n    </tr>\n    <tr>\n      <td>240</td>\n      <td>1.830600</td>\n    </tr>\n    <tr>\n      <td>260</td>\n      <td>1.876100</td>\n    </tr>\n    <tr>\n      <td>280</td>\n      <td>1.829400</td>\n    </tr>\n    <tr>\n      <td>300</td>\n      <td>1.722000</td>\n    </tr>\n    <tr>\n      <td>320</td>\n      <td>1.805200</td>\n    </tr>\n    <tr>\n      <td>340</td>\n      <td>1.755800</td>\n    </tr>\n    <tr>\n      <td>360</td>\n      <td>1.682600</td>\n    </tr>\n    <tr>\n      <td>380</td>\n      <td>1.915300</td>\n    </tr>\n    <tr>\n      <td>400</td>\n      <td>1.666600</td>\n    </tr>\n    <tr>\n      <td>420</td>\n      <td>1.841100</td>\n    </tr>\n    <tr>\n      <td>440</td>\n      <td>1.845900</td>\n    </tr>\n    <tr>\n      <td>460</td>\n      <td>1.733400</td>\n    </tr>\n    <tr>\n      <td>480</td>\n      <td>1.741200</td>\n    </tr>\n    <tr>\n      <td>500</td>\n      <td>1.675900</td>\n    </tr>\n    <tr>\n      <td>520</td>\n      <td>1.760600</td>\n    </tr>\n    <tr>\n      <td>540</td>\n      <td>1.710900</td>\n    </tr>\n    <tr>\n      <td>560</td>\n      <td>1.757400</td>\n    </tr>\n    <tr>\n      <td>580</td>\n      <td>1.738500</td>\n    </tr>\n    <tr>\n      <td>600</td>\n      <td>1.768200</td>\n    </tr>\n    <tr>\n      <td>620</td>\n      <td>1.656100</td>\n    </tr>\n    <tr>\n      <td>640</td>\n      <td>1.777200</td>\n    </tr>\n    <tr>\n      <td>660</td>\n      <td>1.813700</td>\n    </tr>\n    <tr>\n      <td>680</td>\n      <td>1.725800</td>\n    </tr>\n    <tr>\n      <td>700</td>\n      <td>1.771800</td>\n    </tr>\n    <tr>\n      <td>720</td>\n      <td>1.746800</td>\n    </tr>\n    <tr>\n      <td>740</td>\n      <td>1.689900</td>\n    </tr>\n    <tr>\n      <td>760</td>\n      <td>1.786400</td>\n    </tr>\n    <tr>\n      <td>780</td>\n      <td>1.769900</td>\n    </tr>\n    <tr>\n      <td>800</td>\n      <td>1.824700</td>\n    </tr>\n    <tr>\n      <td>820</td>\n      <td>1.693100</td>\n    </tr>\n    <tr>\n      <td>840</td>\n      <td>1.738600</td>\n    </tr>\n    <tr>\n      <td>860</td>\n      <td>1.816100</td>\n    </tr>\n    <tr>\n      <td>880</td>\n      <td>1.749600</td>\n    </tr>\n    <tr>\n      <td>900</td>\n      <td>1.747700</td>\n    </tr>\n    <tr>\n      <td>920</td>\n      <td>1.740400</td>\n    </tr>\n    <tr>\n      <td>940</td>\n      <td>1.719700</td>\n    </tr>\n    <tr>\n      <td>960</td>\n      <td>1.767700</td>\n    </tr>\n    <tr>\n      <td>980</td>\n      <td>1.714800</td>\n    </tr>\n    <tr>\n      <td>1000</td>\n      <td>1.723600</td>\n    </tr>\n    <tr>\n      <td>1020</td>\n      <td>1.681600</td>\n    </tr>\n    <tr>\n      <td>1040</td>\n      <td>1.649800</td>\n    </tr>\n    <tr>\n      <td>1060</td>\n      <td>1.721200</td>\n    </tr>\n    <tr>\n      <td>1080</td>\n      <td>1.703900</td>\n    </tr>\n    <tr>\n      <td>1100</td>\n      <td>1.692300</td>\n    </tr>\n    <tr>\n      <td>1120</td>\n      <td>1.785400</td>\n    </tr>\n    <tr>\n      <td>1140</td>\n      <td>1.691900</td>\n    </tr>\n    <tr>\n      <td>1160</td>\n      <td>1.795500</td>\n    </tr>\n    <tr>\n      <td>1180</td>\n      <td>1.738600</td>\n    </tr>\n    <tr>\n      <td>1200</td>\n      <td>1.681900</td>\n    </tr>\n    <tr>\n      <td>1220</td>\n      <td>1.698600</td>\n    </tr>\n    <tr>\n      <td>1240</td>\n      <td>1.709100</td>\n    </tr>\n    <tr>\n      <td>1260</td>\n      <td>1.664300</td>\n    </tr>\n    <tr>\n      <td>1280</td>\n      <td>1.797000</td>\n    </tr>\n    <tr>\n      <td>1300</td>\n      <td>1.719900</td>\n    </tr>\n    <tr>\n      <td>1320</td>\n      <td>1.675000</td>\n    </tr>\n    <tr>\n      <td>1340</td>\n      <td>1.723900</td>\n    </tr>\n    <tr>\n      <td>1360</td>\n      <td>1.655700</td>\n    </tr>\n    <tr>\n      <td>1380</td>\n      <td>1.657500</td>\n    </tr>\n    <tr>\n      <td>1400</td>\n      <td>1.677300</td>\n    </tr>\n    <tr>\n      <td>1420</td>\n      <td>1.731500</td>\n    </tr>\n    <tr>\n      <td>1440</td>\n      <td>1.697000</td>\n    </tr>\n    <tr>\n      <td>1460</td>\n      <td>1.727900</td>\n    </tr>\n    <tr>\n      <td>1480</td>\n      <td>1.736800</td>\n    </tr>\n    <tr>\n      <td>1500</td>\n      <td>1.736200</td>\n    </tr>\n    <tr>\n      <td>1520</td>\n      <td>1.630900</td>\n    </tr>\n    <tr>\n      <td>1540</td>\n      <td>1.615000</td>\n    </tr>\n    <tr>\n      <td>1560</td>\n      <td>1.668200</td>\n    </tr>\n    <tr>\n      <td>1580</td>\n      <td>1.698000</td>\n    </tr>\n    <tr>\n      <td>1600</td>\n      <td>1.731100</td>\n    </tr>\n    <tr>\n      <td>1620</td>\n      <td>1.794500</td>\n    </tr>\n    <tr>\n      <td>1640</td>\n      <td>1.825500</td>\n    </tr>\n    <tr>\n      <td>1660</td>\n      <td>1.716200</td>\n    </tr>\n    <tr>\n      <td>1680</td>\n      <td>1.668100</td>\n    </tr>\n    <tr>\n      <td>1700</td>\n      <td>1.751900</td>\n    </tr>\n    <tr>\n      <td>1720</td>\n      <td>1.781000</td>\n    </tr>\n    <tr>\n      <td>1740</td>\n      <td>1.744600</td>\n    </tr>\n    <tr>\n      <td>1760</td>\n      <td>1.737100</td>\n    </tr>\n    <tr>\n      <td>1780</td>\n      <td>1.726300</td>\n    </tr>\n    <tr>\n      <td>1800</td>\n      <td>1.733700</td>\n    </tr>\n    <tr>\n      <td>1820</td>\n      <td>1.648200</td>\n    </tr>\n    <tr>\n      <td>1840</td>\n      <td>1.697300</td>\n    </tr>\n    <tr>\n      <td>1860</td>\n      <td>1.783300</td>\n    </tr>\n    <tr>\n      <td>1880</td>\n      <td>1.605100</td>\n    </tr>\n    <tr>\n      <td>1900</td>\n      <td>1.709800</td>\n    </tr>\n    <tr>\n      <td>1920</td>\n      <td>1.699000</td>\n    </tr>\n    <tr>\n      <td>1940</td>\n      <td>1.885000</td>\n    </tr>\n    <tr>\n      <td>1960</td>\n      <td>1.658800</td>\n    </tr>\n    <tr>\n      <td>1980</td>\n      <td>1.669500</td>\n    </tr>\n    <tr>\n      <td>2000</td>\n      <td>1.780000</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=2000, training_loss=1.762493740081787, metrics={'train_runtime': 1009.3499, 'train_samples_per_second': 1.981, 'train_steps_per_second': 1.981, 'total_flos': 5984244203520000.0, 'train_loss': 1.762493740081787, 'epoch': 2.0})"},"metadata":{}}],"execution_count":5},{"cell_type":"code","source":"# # Save the model and tokenizer\n# model.save_pretrained('/kaggle/working/fine_tuned_model_for_rag_1b_instruct')\n# tokenizer.save_pretrained('/kaggle/working/fine_tuned_model_for_rag_1b_instruct')","metadata":{"_uuid":"2b628fb4-dcad-4d9b-8551-35ae92fe1560","_cell_guid":"60d6a1b8-8f7e-481c-a41c-4b801f2dd53e","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-01-11T18:43:32.783279Z","iopub.execute_input":"2025-01-11T18:43:32.783625Z","iopub.status.idle":"2025-01-11T18:43:33.219188Z","shell.execute_reply.started":"2025-01-11T18:43:32.783578Z","shell.execute_reply":"2025-01-11T18:43:33.218329Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Push the model and tokenizer to Hugging Face Hub\nmodel.push_to_hub(\"manishsahu/fine_tuned_model_for_rag_1b_instruct1\")\ntokenizer.push_to_hub(\"manishsahu/fine_tuned_model_for_rag_1b_instruct1\")","metadata":{"_uuid":"f83a72b2-8398-4c58-a618-605ba2ab9ab9","_cell_guid":"fd6773a3-1a1d-4e9d-9863-92d73d520d78","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-01-12T17:44:43.386884Z","iopub.execute_input":"2025-01-12T17:44:43.387194Z","iopub.status.idle":"2025-01-12T17:44:47.758057Z","shell.execute_reply.started":"2025-01-12T17:44:43.387172Z","shell.execute_reply":"2025-01-12T17:44:47.757260Z"},"jupyter":{"outputs_hidden":false}},"outputs":[{"output_type":"display_data","data":{"text/plain":"adapter_model.safetensors:   0%|          | 0.00/3.42M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b7fb3d075f4f43e29a355d24d33d5c1d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/5.17k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1429a93cd9d94c2aa025489aa0fd908f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/17.2M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"68857e2f4ef842f793ae814db87044c9"}},"metadata":{}},{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"CommitInfo(commit_url='https://huggingface.co/manishsahu/fine_tuned_model_for_rag_1b_instruct1/commit/87263236679b0405476f0aec1c1ef12630593c4e', commit_message='Upload tokenizer', commit_description='', oid='87263236679b0405476f0aec1c1ef12630593c4e', pr_url=None, repo_url=RepoUrl('https://huggingface.co/manishsahu/fine_tuned_model_for_rag_1b_instruct1', endpoint='https://huggingface.co', repo_type='model', repo_id='manishsahu/fine_tuned_model_for_rag_1b_instruct1'), pr_revision=None, pr_num=None)"},"metadata":{}}],"execution_count":6},{"cell_type":"code","source":"# Load the fine-tuned model and tokenizer\nmodel = LlamaForCausalLM.from_pretrained('manishsahu/fine_tuned_model_for_rag_1b_instruct1')\ntokenizer = PreTrainedTokenizerFast.from_pretrained('manishsahu/fine_tuned_model_for_rag_1b_instruct1')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-12T17:44:53.472334Z","iopub.execute_input":"2025-01-12T17:44:53.472684Z","iopub.status.idle":"2025-01-12T17:44:58.219510Z","shell.execute_reply.started":"2025-01-12T17:44:53.472655Z","shell.execute_reply":"2025-01-12T17:44:58.218514Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"adapter_config.json:   0%|          | 0.00/830 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b61f8d15e66a460c81ddc9490871f326"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"adapter_model.safetensors:   0%|          | 0.00/3.42M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"59c73fb5296f4fc99d595675ae9af8ff"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/54.6k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f9d1e6bc98d14a31bcb9682b9e69d29c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/17.2M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d8e0a815d9c84453ae62542f66f23457"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/325 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"59b8e6165edf4becbc7c7c1aebb5ec5a"}},"metadata":{}}],"execution_count":7},{"cell_type":"code","source":"from transformers import LlamaForCausalLM, PreTrainedTokenizerFast\n\n# Load the fine-tuned model and tokenizer\nmodel = LlamaForCausalLM.from_pretrained('/kaggle/working/fine_tuned_model_for_rag_1b_instruct')\ntokenizer = PreTrainedTokenizerFast.from_pretrained('/kaggle/working/fine_tuned_model_for_rag_1b_instruct')","metadata":{"_uuid":"f9789ba6-4adf-4390-a665-62a0eeea1030","_cell_guid":"368f9261-d2bc-44ae-8c29-8276ac12c1f7","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-01-11T18:44:24.951117Z","iopub.execute_input":"2025-01-11T18:44:24.951491Z","iopub.status.idle":"2025-01-11T18:44:28.174240Z","shell.execute_reply.started":"2025-01-11T18:44:24.951465Z","shell.execute_reply":"2025-01-11T18:44:28.173264Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Sample question and context\nquestion = \"What is the treatment for hypertension?\"\ncontext = \"Hypertension is commonly treated with lifestyle changes such as diet and exercise. Medications such as ACE inhibitors, calcium channel blockers, and diuretics are often prescribed as well.\"\n\n# Prepare the input in the same format used during training\ninput_text = f\"Question: {question}\\nContext: {context}\\nAnswer:\"\ninputs = tokenizer(input_text, return_tensors='pt')\n\n# Generate the answer\noutput_ids = model.generate(inputs.input_ids, max_length=512)\nanswer = tokenizer.decode(output_ids[0], skip_special_tokens=True)\n\n# Extract the answer part from the generated text\ngenerated_answer = answer.split(\"Answer:\")[1].strip()\n\n# Print the generated answer\nprint(\"Generated Answer:\", generated_answer)","metadata":{"_uuid":"3f2b44fb-d267-4ac0-a060-012a5a6ababf","_cell_guid":"b77f996d-d36f-46f0-a0ce-5c694a092a3b","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-01-12T18:39:14.507717Z","iopub.execute_input":"2025-01-12T18:39:14.508096Z","iopub.status.idle":"2025-01-12T18:41:00.229566Z","shell.execute_reply.started":"2025-01-12T18:39:14.508067Z","shell.execute_reply":"2025-01-12T18:41:00.228582Z"},"jupyter":{"outputs_hidden":false}},"outputs":[{"name":"stderr","text":"The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Generated Answer: The treatment for hypertension typically involves lifestyle modifications, including diet, exercise, and weight loss. Medications such as ACE inhibitors, calcium channel blockers, and diuretics are commonly used to treat hypertension. The choice of medication depends on the severity of hypertension, the presence of kidney disease, and the patient's medical history. Lifestyle modifications are usually the first line of treatment.\n\nReasoning Skill: This question requires the ability to identify the typical treatment approach for hypertension, which is a key aspect of hypertension management. The correct answer is supported by evidence-based guidelines, such as those from the American Heart Association and the American College of Cardiology. The question also requires the ability to distinguish between the typical treatment approach and the specific treatment options for certain patients, such as those with kidney disease or those with a history of heart disease. This requires critical thinking and the ability to analyze complex information. \n\nNote: This question is designed to assess the ability to identify the typical treatment approach for hypertension, which is a key aspect of hypertension management. The correct answer is supported by evidence-based guidelines, and the question requires the ability to distinguish between the typical treatment approach and the specific treatment options for certain patients. The question is not intended to be a multiple-choice question, but rather a descriptive question that requires the test-taker to identify the correct answer based on their knowledge of hypertension management. \n\nThe following skills are relevant to this question:\n\n* Identifying the typical treatment approach for hypertension\n* Distinguishing between the typical treatment approach and specific treatment options\n* Analyzing complex information\n* Recognizing evidence-based guidelines\n* Critical thinking\n* Ability to identify the correct answer based on knowledge of hypertension management. \n\nThe following is the framework for the reasoning skill:\n\n1. Identify the main topic of the question (hypertension treatment)\n2. Identify the key elements of the question (lifestyle modifications, medication, and specific treatment options)\n3. Analyze the information provided (evidence-based guidelines, typical treatment approach)\n4. Evaluate the options (lifestyle modifications, medication, and specific treatment options)\n5. Select the correct answer (typical treatment approach) based on the analysis.\n","output_type":"stream"}],"execution_count":35},{"cell_type":"code","source":"# Sample question and context\nquestion = \"What are the common side effects of Metformin?\"\ncontext = \"Metformin is a medication primarily used for the treatment of type 2 diabetes. It helps control blood sugar levels. Common side effects of Metformin include gastrointestinal symptoms such as nausea, vomiting, diarrhea, abdominal pain, and loss of appetite. Long-term use may lead to vitamin B12 deficiency.\"\n\n# Prepare the input in the same format used during training\ninput_text = f\"Question: {question}\\nContext: {context}\\nAnswer:\"\ninputs = tokenizer(input_text, return_tensors='pt')\n\n# Generate the answer\noutput_ids = model.generate(inputs.input_ids, max_length=512)\nanswer = tokenizer.decode(output_ids[0], skip_special_tokens=True)\n\n# Extract the answer part from the generated text\ngenerated_answer = answer.split(\"Answer:\")[1].strip()\n\n# Print the generated answer\nprint(\"Generated Answer:\", generated_answer)","metadata":{"_uuid":"ec82f61c-2f20-4690-98db-583dc8af890f","_cell_guid":"b075e966-2d90-4448-a689-6a693fd17995","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-01-12T18:41:00.230896Z","iopub.execute_input":"2025-01-12T18:41:00.231313Z","iopub.status.idle":"2025-01-12T18:41:43.437380Z","shell.execute_reply.started":"2025-01-12T18:41:00.231285Z","shell.execute_reply":"2025-01-12T18:41:43.436594Z"},"jupyter":{"outputs_hidden":false}},"outputs":[{"name":"stderr","text":"The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Generated Answer: The common side effects of Metformin include gastrointestinal symptoms such as nausea, vomiting, diarrhea, abdominal pain, and loss of appetite. These side effects are usually mild and temporary. In some cases, long-term use of Metformin may lead to vitamin B12 deficiency.\n\nReasoning Skill: The question requires the test-taker to identify the common side effects of Metformin. This involves analyzing the information provided in the question and using the knowledge of the subject matter to make an educated inference. The test-taker must also be able to distinguish between the common side effects and the long-term side effects of Metformin, which requires critical thinking and analysis of the information. This type of question is appropriate for assessing the reasoning skill of Identifying Pros And Cons, as it requires the test-taker to evaluate the potential side effects of a medication and make an informed decision.\n","output_type":"stream"}],"execution_count":36},{"cell_type":"code","source":"0+8","metadata":{"_uuid":"dd865a1b-1e77-4bcb-b5cb-6a857c9c9c43","_cell_guid":"ded36ae6-807c-46ab-9621-440d42805c46","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## RAG Implementation","metadata":{"_uuid":"9353c033-506a-4e2b-8c36-79101ea32cc9","_cell_guid":"8245e2c2-49c3-496b-a900-fd5bffcddc96","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"import faiss\nimport numpy as np\nfrom sentence_transformers import SentenceTransformer\n\n# Initialize the SentenceTransformer model for embedding\nembedder = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')\n\n# Function to generate context embeddings and create FAISS index\ndef create_faiss_index(contexts):\n    # Step 1: Generate sentence embeddings for contexts\n    context_embeddings = embedder.encode(contexts, show_progress_bar=True, device='cuda')\n\n    # Step 2: Convert embeddings to numpy array (required by FAISS)\n    context_embeddings = np.array(context_embeddings)\n\n    # Step 3: Create FAISS index and add embeddings\n    dimension = context_embeddings.shape[1]  # Dimension of the embeddings\n    faiss_index = faiss.IndexFlatL2(dimension)  # L2 distance metric for similarity search\n    faiss_index.add(context_embeddings)\n\n    # Step 4: Save the index and embeddings\n    faiss.write_index(faiss_index, '/kaggle/working/path_to_faiss_index')\n    np.save('/kaggle/working/path_to_context_embeddings.npy', context_embeddings)\n\n    return faiss_index, context_embeddings\n\n# Function to retrieve the most relevant context for a query\ndef search_query(query, faiss_index, context_embeddings, contexts, top_k=5):\n    # Step 1: Generate query embedding\n    query_embedding = embedder.encode([query], convert_to_tensor=True, device='cuda')\n    query_embedding = query_embedding.cpu().numpy()\n\n    # Step 2: Search the FAISS index for the top_k most similar contexts\n    distances, indices = faiss_index.search(query_embedding, top_k)\n\n    # Step 3: Retrieve the contexts and distances\n    results = []\n    for i in range(top_k):\n        context_idx = indices[0][i]  # Get the index of the context\n        distance = distances[0][i]   # Get the distance (similarity measure)\n        context = contexts[context_idx]  # Retrieve the actual context text\n        results.append((context, distance))\n    \n    return results\n\n# # Example usage: Loading PubMed Dataset\n# from datasets import load_dataset\n\n# # Load the PubMed QA dataset\n# pubmed = load_dataset('pubmed_qa', 'pqa_labeled', split='train')\n\n# Get the context data from PubMed (assuming 'context' field is available)\ncontexts = pubmed['context']  # List of context texts\n\n# Save contexts (if you need to store and load them later)\nimport pickle\nwith open('/kaggle/working/path_to_contexts.pkl', 'wb') as f:\n    pickle.dump(contexts, f)\n\n# Step 1: Create FAISS index for the contexts\nfaiss_index, context_embeddings = create_faiss_index(contexts)","metadata":{"_uuid":"336480f0-ffd4-4dad-aa69-fda98e94fb78","_cell_guid":"16695993-5f22-4936-9265-0b363d33364b","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-01-12T18:17:06.538340Z","iopub.execute_input":"2025-01-12T18:17:06.538642Z","iopub.status.idle":"2025-01-12T18:17:09.121421Z","shell.execute_reply.started":"2025-01-12T18:17:06.538620Z","shell.execute_reply":"2025-01-12T18:17:09.120647Z"},"jupyter":{"outputs_hidden":false}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/32 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"38700e9f1ef14417b38d2c1b62c4e056"}},"metadata":{}}],"execution_count":22},{"cell_type":"code","source":"# Now, you can give a query, and the system will retrieve relevant contexts\nquery = \"What is the role of inflammation in heart disease?\"\nresults = search_query(query, faiss_index, context_embeddings, contexts, top_k=3)\n\n# Display the top matching contexts for the query\n# print(f\"Top matching contexts for the query: {query}\\n\")\nfor context, distance in results:\n    print(f\"Context: {context} | Distance: {distance:.3f}\\n\")\n    \n# for c, d in results:\n#     print(c['contexts'],'\\n')","metadata":{"_uuid":"60309a61-d5ef-4d6a-befc-64ac46abc360","_cell_guid":"1a457cf6-54b5-423a-97af-124eeb42508f","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-01-11T19:49:30.099715Z","iopub.execute_input":"2025-01-11T19:49:30.100055Z","iopub.status.idle":"2025-01-11T19:49:30.130156Z","shell.execute_reply.started":"2025-01-11T19:49:30.100032Z","shell.execute_reply":"2025-01-11T19:49:30.129369Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Get answer using RAG","metadata":{"_uuid":"e386b5a7-4534-43d4-b763-12da6fa80689","_cell_guid":"b3c4a295-71aa-416e-815a-63351b14c431","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"def get_answer(question, faiss_index, context_embeddings, contexts, embedder, model, tokenizer):\n    # Step 1: Encode the question and retrieve the most relevant context\n    question_embedding = embedder.encode([question])\n    distances, indices = faiss_index.search(np.array(question_embedding), 1)\n    top_context = contexts[indices[0][0]]\n    \n    # Step 2: Generate the answer using the fine-tuned model\n    # input_text = f\"<question> {question} <context> {top_context}\"\n    input_text = f\"Question: {question}\\nContext: {top_context['contexts']}\\nAnswer:\"\n    answer_ids = model.generate(tokenizer(input_text, return_tensors='pt').input_ids, max_length=512)\n    answer = tokenizer.decode(answer_ids[0], skip_special_tokens=True)\n\n    # Extract the answer part from the generated text\n    generated_answer = answer.split(\"Answer:\")[1].strip()\n    \n    return generated_answer, top_context","metadata":{"_uuid":"cbd7659a-8dbb-4dd3-a648-01fec081e377","_cell_guid":"4b9bf720-702b-4d14-a268-399ab62296c8","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-01-12T18:37:00.762170Z","iopub.execute_input":"2025-01-12T18:37:00.762506Z","iopub.status.idle":"2025-01-12T18:37:00.767660Z","shell.execute_reply.started":"2025-01-12T18:37:00.762475Z","shell.execute_reply":"2025-01-12T18:37:00.766823Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":31},{"cell_type":"code","source":"# Example question\nquestion = \"What is the role of inflammation in heart disease?\"\n\n# Generate the answer\nanswer, c = get_answer(question, faiss_index, context_embeddings, contexts, embedder, model, tokenizer)\n\nprint(f\"Question: {question}\\n\")\nprint(f\"Answer: {answer}\\n\")\n# print(c)","metadata":{"_uuid":"d0cd8cdf-f463-4a62-a954-8dcc38306372","_cell_guid":"00a350b8-fe87-4580-afeb-808dd409d609","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-01-12T18:44:59.003413Z","iopub.execute_input":"2025-01-12T18:44:59.003745Z","iopub.status.idle":"2025-01-12T18:45:58.448890Z","shell.execute_reply.started":"2025-01-12T18:44:59.003720Z","shell.execute_reply":"2025-01-12T18:45:58.447981Z"},"jupyter":{"outputs_hidden":false}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8bcde5dd244d4a1fa7887c7aff8b6e3d"}},"metadata":{}},{"name":"stderr","text":"The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Question: What is the role of inflammation in heart disease?\n\nAnswer: ['The role of inflammation in heart disease is multifaceted. It is well established that white adipose tissue (WAT) produces numerous proinflammatory and proatherogenic cytokines and chemokines. These signals are produced in response to the accumulation of lipids and the presence of metabolic stressors. Adipose tissue-derived chemotactic signals play a crucial role in the migration of leukocytes to sites of inflammation and the recruitment of inflammatory cells to the arterial wall. The migration of these cells contributes to the development of atherosclerosis and the progression of cardiovascular disease. The role of inflammation in the development of atherosclerosis is complex and multifaceted. It involves the recruitment of macrophages and T cells to the arterial wall, the production of proinflammatory cytokines and chemokines, and the promotion of atherogenesis.']\nNote: The question is presented in a way that it is somewhat ambiguous and open to interpretation. However, based on the context provided, it appears that the question is asking about the role of inflammation in heart disease, specifically in the context of white adipose tissue (WAT) and the role of chemotactic signals\n\n","output_type":"stream"}],"execution_count":37},{"cell_type":"code","source":"# Example question\nquestion = \"What are the common side effects of Metformin?\"\n\n# Generate the answer\nanswer, c = get_answer(question, faiss_index, context_embeddings, contexts, embedder, model, tokenizer)\n\nprint(f\"Question: {question}\\n\")\nprint(f\"Answer: {answer}\\n\")\n# print(c)","metadata":{"_uuid":"eae24fb6-1661-44f1-9b82-2c9e9c361d16","_cell_guid":"c711dc7a-7ed2-4537-a039-5b729c0bed60","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-01-12T18:37:13.795512Z","iopub.execute_input":"2025-01-12T18:37:13.795888Z","iopub.status.idle":"2025-01-12T18:37:32.705856Z","shell.execute_reply.started":"2025-01-12T18:37:13.795824Z","shell.execute_reply":"2025-01-12T18:37:32.705012Z"},"jupyter":{"outputs_hidden":false}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"94371ac70f274a19913d1cdfc8cda01d"}},"metadata":{}},{"name":"stderr","text":"The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Question: What are the common side effects of Metformin?\n\nAnswer: ['The common side effects of Metformin include nausea, gastrointestinal disturbances, diarrhea, and lactic acidosis. The most common side effects were nausea and gastrointestinal disturbances. Metformin was associated with a higher incidence of nausea and gastrointestinal disturbances compared with the sulfonylurea group.']\n\n","output_type":"stream"}],"execution_count":32},{"cell_type":"code","source":"# Example question\nquestion = \"What is the treatment for hypertension?\"\n\n# Generate the answer\nanswer, c = get_answer(question, faiss_index, context_embeddings, contexts, embedder, model, tokenizer)\n\nprint(f\"Question: {question}\\n\")\nprint(f\"Answer: {answer}\\n\")\n# print(c)","metadata":{"_uuid":"78824a9b-1c25-4d9d-a76c-f20de58f6810","_cell_guid":"6c4ea202-840b-4670-b5a5-dd8937d8c595","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-01-12T18:38:14.360415Z","iopub.execute_input":"2025-01-12T18:38:14.360789Z","iopub.status.idle":"2025-01-12T18:38:54.574937Z","shell.execute_reply.started":"2025-01-12T18:38:14.360758Z","shell.execute_reply":"2025-01-12T18:38:54.574086Z"},"jupyter":{"outputs_hidden":false}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"116b9e5e2a994000a9e2d81e4fcf8ef5"}},"metadata":{}},{"name":"stderr","text":"The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Question: What is the treatment for hypertension?\n\nAnswer: ['The treatment for hypertension is not specified in the text. However, the treatment for hypertension is typically lifestyle modifications, such as dietary changes, exercise, and weight loss, and may include the use of medications to control blood pressure. The DASH study was a controlled feeding study that compared the effects of different diets on blood pressure in individuals with prehypertension or stage 1 hypertension. The study found no difference in caloric intake between AA and non-AA women.']\n\nReasoning Skill: This question requires the test-taker to analyze the purpose and design of the DASH study and identify the specific treatment for hypertension. The test-taker must also recognize that the DASH study was a controlled feeding study and that the results may have been influenced by the\n\n","output_type":"stream"}],"execution_count":34},{"cell_type":"markdown","source":"## Flask implementation","metadata":{"_uuid":"0c8d78a9-fe4d-4908-a162-de95bdf2db2b","_cell_guid":"7271c86a-ba09-419d-b6ce-e9f570cf13e0","collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"!pip install Flask pyngrok transformers flask-ngrok","metadata":{"_uuid":"1e0dc7fd-fb48-4712-9f0e-501c74c75efb","_cell_guid":"97b6b8dd-c3bc-4408-8feb-85727f05eb14","trusted":true,"collapsed":true,"jupyter":{"outputs_hidden":true},"execution":{"iopub.status.busy":"2025-01-12T17:48:44.252189Z","iopub.execute_input":"2025-01-12T17:48:44.252490Z","iopub.status.idle":"2025-01-12T17:48:47.815097Z","shell.execute_reply.started":"2025-01-12T17:48:44.252469Z","shell.execute_reply":"2025-01-12T17:48:47.814089Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: Flask in /usr/local/lib/python3.10/dist-packages (2.2.5)\nRequirement already satisfied: pyngrok in /usr/local/lib/python3.10/dist-packages (7.2.3)\nRequirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.48.0)\nCollecting flask-ngrok\n  Downloading flask_ngrok-0.0.25-py3-none-any.whl.metadata (1.8 kB)\nRequirement already satisfied: Werkzeug>=2.2.2 in /usr/local/lib/python3.10/dist-packages (from Flask) (3.0.4)\nRequirement already satisfied: Jinja2>=3.0 in /usr/local/lib/python3.10/dist-packages (from Flask) (3.1.4)\nRequirement already satisfied: itsdangerous>=2.0 in /usr/local/lib/python3.10/dist-packages (from Flask) (2.2.0)\nRequirement already satisfied: click>=8.0 in /usr/local/lib/python3.10/dist-packages (from Flask) (8.1.7)\nRequirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.10/dist-packages (from pyngrok) (6.0.2)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\nRequirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.27.1)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.1)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.9.11)\nRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\nRequirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.21.0)\nRequirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\nRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.5)\nRequirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (2024.6.1)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (4.12.2)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from Jinja2>=3.0->Flask) (2.1.5)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.8.30)\nDownloading flask_ngrok-0.0.25-py3-none-any.whl (3.1 kB)\nInstalling collected packages: flask-ngrok\nSuccessfully installed flask-ngrok-0.0.25\n","output_type":"stream"}],"execution_count":14},{"cell_type":"code","source":"!ngrok authtoken 2rXNsTZZgcrQc5rdhcbdkwbw487Y8JsNCyYe  # I've modified this it, use your won","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-12T17:45:19.777063Z","iopub.execute_input":"2025-01-12T17:45:19.777398Z","iopub.status.idle":"2025-01-12T17:45:20.184259Z","shell.execute_reply.started":"2025-01-12T17:45:19.777375Z","shell.execute_reply":"2025-01-12T17:45:20.183331Z"}},"outputs":[{"name":"stdout","text":"Authtoken saved to configuration file: /root/.config/ngrok/ngrok.yml\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"from pyngrok import ngrok\n\n# Set the Flask app port\nport = 5000\n\n# Start Ngrok tunnel to the Flask app\npublic_url = ngrok.connect(port)\n\nprint(f\"Flask app is running at: {public_url}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-12T18:22:24.591579Z","iopub.execute_input":"2025-01-12T18:22:24.591981Z","iopub.status.idle":"2025-01-12T18:22:24.897822Z","shell.execute_reply.started":"2025-01-12T18:22:24.591944Z","shell.execute_reply":"2025-01-12T18:22:24.896942Z"}},"outputs":[{"name":"stdout","text":"Flask app is running at: NgrokTunnel: \"https://58a2-35-190-138-166.ngrok-free.app\" -> \"http://localhost:5000\"\n","output_type":"stream"}],"execution_count":26},{"cell_type":"code","source":"from flask import Flask, request, jsonify, render_template_string\nfrom transformers import LlamaForCausalLM, PreTrainedTokenizerFast\nfrom flask_ngrok import run_with_ngrok\nimport nest_asyncio\n\nnest_asyncio.apply()\n\napp = Flask(__name__)\nrun_with_ngrok(app)  # Start ngrok when the app is run\n\n# Load your fine-tuned model and tokenizer\nmodel = LlamaForCausalLM.from_pretrained('manishsahu/fine_tuned_model_for_rag_1b_instruct1')\ntokenizer = PreTrainedTokenizerFast.from_pretrained('manishsahu/fine_tuned_model_for_rag_1b_instruct1')\n\n# Assume you have your FAISS index, context embeddings, and the list of contexts\nfaiss_index = faiss.read_index('/kaggle/working/path_to_faiss_index')\ncontext_embeddings = np.load('/kaggle/working/path_to_context_embeddings.npy')\n# Load the contexts from the pickle file\nwith open('/kaggle/working/path_to_contexts.pkl', 'rb') as f:\n    contexts = pickle.load(f)\n# contexts = [{'contexts': 'context text here'}]  # Load your contexts accordingly\n\n@app.route(\"/\")\ndef home():\n    return render_template_string(\"\"\"\n    <h1>Ask a Question</h1>\n    <form action=\"/ask\" method=\"post\">\n        <input type=\"text\" name=\"question\" placeholder=\"Enter your question\" required>\n        <input type=\"submit\" value=\"Ask\">\n    </form>\n    \"\"\")\n\n@app.route(\"/ask\", methods=[\"POST\"])\ndef ask():\n    question = request.form[\"question\"]\n    \n    # Step 1: Encode the question and retrieve the most relevant context\n    question_embedding = embedder.encode([question])\n    distances, indices = faiss_index.search(np.array(question_embedding), 1)\n    top_context = contexts[indices[0][0]]\n    \n    # Step 2: Generate the answer using the fine-tuned model\n    input_text = f\"Question: {question}\\nContext: {top_context['contexts']}\\nAnswer:\"\n    answer_ids = model.generate(tokenizer(input_text, return_tensors='pt').input_ids, max_length=512)\n    answer = tokenizer.decode(answer_ids[0], skip_special_tokens=True)\n    \n    # Extract the answer part from the generated text\n    generated_answer = answer.split(\"Answer:\")[1].strip()\n    \n    return render_template_string(\"\"\"\n    <h1>Your Question:</h1>\n    <p>{{ question }}</p>\n    <h1>Answer:</h1>\n    <p>{{ answer }}</p>\n    <a href=\"/\">Ask another question</a>\n    \"\"\", question=question, answer=generated_answer)\n\nif __name__ == \"__main__\":\n    app.run()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-12T18:25:55.684068Z","iopub.execute_input":"2025-01-12T18:25:55.684444Z","iopub.status.idle":"2025-01-12T18:36:52.354406Z","shell.execute_reply.started":"2025-01-12T18:25:55.684415Z","shell.execute_reply":"2025-01-12T18:36:52.353219Z"}},"outputs":[{"name":"stdout","text":" * Serving Flask app '__main__'\n * Debug mode: off\n * Running on http://58a2-35-190-138-166.ngrok-free.app\n * Traffic stats available on http://127.0.0.1:4040\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fc6df775a6664d81a698cd635ee62115"}},"metadata":{}},{"name":"stderr","text":"The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4d4c45b096494a23a8f9109779d367c1"}},"metadata":{}},{"name":"stderr","text":"The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b680eacffd864c8189ba532621757fc1"}},"metadata":{}},{"name":"stderr","text":"The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"}],"execution_count":29},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}